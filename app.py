#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ for ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
"""

from flask import Flask, render_template, jsonify, request
from pathlib import Path
import json
import pandas as pd
import datetime as dt
from analysis_dashboard import extract_monthly_data, FILES
from data_loader import get_data_loader
import streamlit as st

app = Flask(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
global_data = None
base_data = None

def load_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ä¿å­˜"""
    global global_data, base_data
    
    try:
        loader = get_data_loader()
        available_months = loader.get_available_months()
        
        if not available_months:
            print("è­¦å‘Š: åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        # æœ€æ–°æœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        target_month = available_months[0]
        basic_data, detail_data, summary_data = loader.load_analysis_data(target_month)
        
        dfs = {}
        if basic_data:
            dfs['basic'] = extract_monthly_data(basic_data)
        if detail_data:
            dfs['detail'] = extract_monthly_data(detail_data)
        if summary_data:
            dfs['monthly'] = extract_monthly_data(summary_data)
        
        # ç©ºã®DataFrameã‚’é™¤å¤–
        dfs = {k: v for k, v in dfs.items() if not v.empty}
        
        if not dfs:
            print("è­¦å‘Š: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
            
    except Exception as e:
        print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    base_data = pd.concat(dfs.values(), ignore_index=True)
    
    # å‰å‡¦ç†
    base_data['date'] = pd.to_datetime(base_data['date'], errors='coerce')
    base_data['month'] = base_data['date'].dt.to_period('M').astype(str)
    base_data['join_date'] = pd.to_datetime(base_data['join_date'], errors='coerce')
    
    # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã‚’çµ±ä¸€
    base_data['date'] = base_data['date'].dt.tz_localize(None)
    base_data['join_date'] = base_data['join_date'].dt.tz_localize(None)
    
    base_data['tenure_months'] = ((base_data['date'] - base_data['join_date']) / pd.Timedelta(days=30)).round()
    
    def bucket(m):
        if pd.isna(m):
            return "Unknown"
        if m < 3:
            return "<3mo"
        if m < 6:
            return "3â€“6mo"
        if m < 12:
            return "6â€“12mo"
        return ">=12mo"
    
    base_data['tenure_grp'] = base_data['tenure_months'].apply(bucket)
    
    # æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿
    monthly = (
        base_data.groupby('month')
            .agg(calls=('calls','sum'),
                 appointments=('appointments','sum'),
                 hours=('call_hours','sum'))
            .assign(eff=lambda x: x.calls / x.hours,
                    conv=lambda x: x.appointments / x.calls * 100)
            .reset_index()
    )
    
    # æ”¯åº— Ã— æœˆ
    branch_month = (
        base_data.groupby(['month','branch'])
            .agg(calls=('calls','sum'),
                 hours=('call_hours','sum'))
            .assign(eff=lambda x: x.calls / x.hours)
            .reset_index()
    )
    
    # åœ¨ç±æœŸé–“åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    tenure_perf = (
        base_data.groupby('tenure_grp')
            .agg(calls=('calls','sum'),
                 hours=('call_hours','sum'),
                 appointments=('appointments','sum'))
            .assign(eff=lambda x: x.calls / x.hours,
                    conv=lambda x: x.appointments / x.calls * 100)
            .reset_index()
    )
    
    # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
    summary = {
        'total_calls': int(base_data['calls'].sum()),
        'total_hours': int(base_data['call_hours'].sum()),
        'total_appointments': int(base_data['appointments'].sum()),
        'avg_efficiency': float(base_data['calls'].sum() / base_data['call_hours'].sum()) if base_data['call_hours'].sum() > 0 else 0
    }
    
    global_data = {
        'monthly': monthly.to_dict(orient="records"),
        'branch_trend': branch_month.to_dict(orient="records"),
        'tenure_perf': tenure_perf.to_dict(orient="records"),
        'summary': summary,
        'available_months': sorted(monthly['month'].unique(), reverse=True)[:6]
    }
    
    return True

@app.route('/')
def dashboard():
    """ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸"""
    if global_data is None:
        if not load_data():
            return "ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ", 500
    
    selected_month = global_data['available_months'][0] if global_data['available_months'] else None
    
    # é¸æŠã•ã‚ŒãŸæœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    month_data = get_month_data(selected_month)
    
    return render_template('dashboard_template.html',
                         generated_at=dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
                         monthly=global_data['monthly'],
                         branch_trend=global_data['branch_trend'],
                         branch_latest=month_data['branch_latest'],
                         staff_eff=month_data['staff_eff'],
                         staff_conv=month_data['staff_conv'],
                         tenure_perf=global_data['tenure_perf'],
                         summary=global_data['summary'],
                         available_months=global_data['available_months'],
                         selected_month=selected_month)

@app.route('/api/month_data/<month>')
def api_month_data(month):
    """æŒ‡å®šã•ã‚ŒãŸæœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    if global_data is None:
        if not load_data():
            return jsonify({'error': 'ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ'}), 500
    
    month_data = get_month_data(month)
    return jsonify(month_data)

def get_month_data(month):
    """æŒ‡å®šã•ã‚ŒãŸæœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    if month is None or base_data is None:
        return {
            'branch_latest': [],
            'staff_eff': [],
            'staff_conv': []
        }
    
    month_df = base_data[base_data['month'] == month]
    
    # æ”¯åº—åˆ¥ãƒ‡ãƒ¼ã‚¿
    branch_latest = (
        month_df.groupby('branch')
            .agg(calls=('calls','sum'),
                 hours=('call_hours','sum'),
                 appointments=('appointments','sum'))
            .assign(eff=lambda x: x.calls / x.hours,
                    conv=lambda x: x.appointments / x.calls * 100)
            .sort_values('eff', ascending=False)
            .reset_index()
    )
    
    # ã‚¹ã‚¿ãƒƒãƒ•åŠ¹ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    staff_eff = (
        month_df.groupby('staff')
            .agg(calls=('calls','sum'),
                 hours=('call_hours','sum'))
            .assign(eff=lambda x: x.calls / x.hours)
            .sort_values('eff', ascending=False)
            .head(5)
            .reset_index()
    )
    
    # ã‚¹ã‚¿ãƒƒãƒ•æˆç´„ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    staff_conv = (
        month_df.groupby('staff')
            .agg(calls=('calls','sum'),
                 appointments=('appointments','sum'))
            .assign(conv=lambda x: x.appointments / x.calls * 100)
            .sort_values('conv', ascending=False)
            .head(5)
            .reset_index()
    )
    
    return {
        'branch_latest': branch_latest.to_dict(orient="records"),
        'staff_eff': staff_eff.to_dict(orient="records"),
        'staff_conv': staff_conv.to_dict(orient="records")
    }

def get_debug_info():
    # This function is not provided in the original file or the new code block
    # It's assumed to exist as it's called in the new code block
    pass

if __name__ == '__main__':
    # ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰ã«èª­ã¿è¾¼ã¿
    if load_data():
        print("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
        app.run(debug=True, host='0.0.0.0', port=5001)
    else:
        print("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")

    if st.button("ğŸ” è©³ç´°ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å–å¾—", type="primary"):
        with st.spinner("è©³ç´°æƒ…å ±ã‚’å–å¾—ä¸­..."):
            debug_info = get_debug_info()
            
            # åŸºæœ¬è¨­å®šæƒ…å ±
            st.subheader("ğŸ”§ è¨­å®šçŠ¶æ…‹")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**PRODUCTION_MODE**: {debug_info['config']['PRODUCTION_MODE']}")
                st.write(f"**GOOGLE_DRIVE_ENABLED**: {debug_info['config']['GOOGLE_DRIVE_ENABLED']}")
                st.write(f"**USE_LOCAL_FALLBACK**: {debug_info['config']['USE_LOCAL_FALLBACK']}")
                st.write(f"**FOLDER_ID**: {debug_info['config']['GOOGLE_DRIVE_FOLDER_ID']}")
            
            # Streamlit SecretsçŠ¶æ…‹
            st.subheader("ğŸ” Streamlit SecretsçŠ¶æ…‹")
            if debug_info['secrets']['available']:
                st.success(f"âœ… Secretsåˆ©ç”¨å¯èƒ½")
                st.write(f"**è¨­å®šæ¸ˆã¿ã‚­ãƒ¼**: {debug_info['secrets']['keys']}")
                st.write(f"**google_driveã‚­ãƒ¼**: {debug_info['secrets']['google_drive_keys']}")
                st.write(f"**service_accounté•·ã•**: {debug_info['secrets']['service_account_length']}")
                
                # Service Account JSONè©³ç´°æ¤œè¨¼
                st.subheader("ğŸ” Service Account JSONè©³ç´°")
                service_account_data = st.secrets.get("google_drive", {}).get("service_account", "")
                
                if service_account_data:
                    try:
                        import json
                        parsed_json = json.loads(service_account_data)
                        st.success("âœ… JSONå½¢å¼: æ­£å¸¸")
                        
                        # é‡è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
                        required_fields = ["type", "project_id", "private_key_id", "private_key", "client_email", "client_id", "auth_uri", "token_uri"]
                        missing_fields = [field for field in required_fields if field not in parsed_json]
                        
                        if missing_fields:
                            st.error(f"âŒ ä¸è¶³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {missing_fields}")
                        else:
                            st.success("âœ… å¿…è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: å…¨ã¦å­˜åœ¨")
                        
                        # private_keyã®è©³ç´°ç¢ºèª
                        private_key = parsed_json.get("private_key", "")
                        if private_key:
                            st.write(f"**private_keyé•·ã•**: {len(private_key)}")
                            st.write(f"**private_keyé–‹å§‹**: {private_key[:50]}...")
                            st.write(f"**æ”¹è¡Œæ–‡å­—æ•°**: {private_key.count('\\n')}")
                            
                            # PEMå½¢å¼ã®ç¢ºèª
                            if "-----BEGIN PRIVATE KEY-----" in private_key and "-----END PRIVATE KEY-----" in private_key:
                                st.success("âœ… PEMå½¢å¼ãƒ˜ãƒƒãƒ€ãƒ¼: æ­£å¸¸")
                            else:
                                st.error("âŒ PEMå½¢å¼ãƒ˜ãƒƒãƒ€ãƒ¼: ä¸æ­£")
                            
                            # æ”¹è¡Œæ–‡å­—ã®å•é¡Œç¢ºèª
                            if "\\n" in private_key:
                                st.warning("âš ï¸ ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚ŒãŸæ”¹è¡Œæ–‡å­—ã‚’æ¤œå‡º")
                                st.info("ğŸ’¡ è§£æ±ºæ–¹æ³•: private_keyã®\\nã‚’å®Ÿéš›ã®æ”¹è¡Œæ–‡å­—ã«ç½®æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
                        else:
                            st.error("âŒ private_keyãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        
                    except json.JSONDecodeError as e:
                        st.error(f"âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
                        st.text("JSONã®å…ˆé ­50æ–‡å­—:")
                        st.code(service_account_data[:50])
                else:
                    st.error("âŒ service_accountãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # ç’°å¢ƒå¤‰æ•°çŠ¶æ…‹
            st.subheader("ğŸŒ ç’°å¢ƒå¤‰æ•°çŠ¶æ…‹")
            if debug_info['environment']['GOOGLE_SERVICE_ACCOUNT']:
                st.success("âœ… GOOGLE_SERVICE_ACCOUNT: è¨­å®šæ¸ˆã¿")
                st.write(f"**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID**: {debug_info['environment']['project_id']}")
                st.write(f"**ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ¡ãƒ¼ãƒ«**: {debug_info['environment']['client_email']}")
            else:
                st.error("âŒ GOOGLE_SERVICE_ACCOUNT: æœªè¨­å®š")
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            st.subheader("ğŸ”— æ¥ç¶šãƒ†ã‚¹ãƒˆ")
            
            col1, col2 = st.columns(2)
            with col1:
                if debug_info['connection']['force_refresh_success']:
                    st.success("âœ… å¼·åˆ¶ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆ: æˆåŠŸ")
                else:
                    st.error("âŒ å¼·åˆ¶ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆ: å¤±æ•—")
                    st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {debug_info['connection']['force_refresh_error']}")
            
            with col2:
                if debug_info['connection']['normal_success']:
                    st.success("âœ… é€šå¸¸ãƒ†ã‚¹ãƒˆ: æˆåŠŸ")
                else:
                    st.error("âŒ é€šå¸¸ãƒ†ã‚¹ãƒˆ: å¤±æ•—")
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {debug_info['connection']['normal_error']}")
            
            # è§£æ±ºæ–¹æ³•ã®ææ¡ˆ
            if not debug_info['connection']['normal_success']:
                st.subheader("ğŸ’¡ è§£æ±ºæ–¹æ³•")
                if "Unable to load PEM file" in str(debug_info['connection']['normal_error']):
                    st.info("""
                    **private_keyã®æ”¹è¡Œæ–‡å­—å•é¡Œã®è§£æ±ºæ–¹æ³•:**
                    
                    1. Google Cloud Consoleã‹ã‚‰Service Accountã‚­ãƒ¼ã‚’å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    2. JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦ã€private_keyãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å†…å®¹ã‚’ã‚³ãƒ”ãƒ¼
                    3. Streamlit Cloudã®è¨­å®šã§ã€private_keyã®å€¤ã®\\nã‚’å®Ÿéš›ã®æ”¹è¡Œã«ç½®æ›
                    4. ã¾ãŸã¯ã€ä¸‹è¨˜ã®ãƒœã‚¿ãƒ³ã§è‡ªå‹•ä¿®æ­£ã‚’è©¦è¡Œ
                    """)
                    
                    if st.button("ğŸ”§ private_keyè‡ªå‹•ä¿®æ­£ã‚’è©¦è¡Œ"):
                        try:
                            import json
                            service_account_data = st.secrets.get("google_drive", {}).get("service_account", "")
                            parsed_json = json.loads(service_account_data)
                            
                            # private_keyã®ä¿®æ­£
                            if "private_key" in parsed_json:
                                original_key = parsed_json["private_key"]
                                fixed_key = original_key.replace("\\n", "\n")
                                
                                st.text("ä¿®æ­£å‰ã®æ”¹è¡Œæ–‡å­—æ•°:")
                                st.code(f"\\næ–‡å­—æ•°: {original_key.count('\\n')}")
                                st.text("ä¿®æ­£å¾Œã®æ”¹è¡Œæ–‡å­—æ•°:")
                                st.code(f"å®Ÿéš›ã®æ”¹è¡Œæ•°: {fixed_key.count(chr(10))}")
                                
                                # ä¿®æ­£ã—ãŸJSONã‚’è¡¨ç¤ºï¼ˆå®Ÿéš›ã®é©ç”¨ã¯æ‰‹å‹•ã§è¡Œã†å¿…è¦ãŒã‚ã‚‹ï¼‰
                                parsed_json["private_key"] = fixed_key
                                st.text("ä¿®æ­£å¾Œã®JSONï¼ˆæ‰‹å‹•ã§Streamlit Secretsã«è¨­å®šã—ã¦ãã ã•ã„ï¼‰:")
                                st.code(json.dumps(parsed_json, indent=2))
                            
                        except Exception as e:
                            st.error(f"è‡ªå‹•ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {str(e)}") 